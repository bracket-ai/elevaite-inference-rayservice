apiVersion: v1
kind: Pod
metadata:
  name: test-gpu
spec:
  volumes:
    - name: "s3-storage"
      persistentVolumeClaim:
        claimName: "s3-claim"
  containers:
  - name: test-gpu-container
    image: pytorch/pytorch:2.4.0-cuda12.1-cudnn9-runtime
    resources:
      limits:
        nvidia.com/gpu: 1  # Request 1 GPU
    volumeMounts:
      - mountPath: "/data_bucket"
        name: "s3-storage"
    command: ["/bin/bash"]
    stdin: true
    tty: true
